{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Import data\n",
    "url = r'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "dataframe = pd.read_csv(url, \n",
    "                        sep = ',', \n",
    "                        header = None, \n",
    "                        index_col = None,\n",
    "                        na_values = '?')\n",
    "\n",
    "# Add column names\n",
    "name_list = ['age', 'sex', 'cp','trestbps', 'chol', 'fbs','restecg',\n",
    "             'thalac','exang','oldpeak','slope','ca','thal','num']\n",
    "dataframe.columns = name_list\n",
    "\n",
    "# Fill missing data with columnwise median values\n",
    "dataframe = dataframe.fillna(dataframe.median())\n",
    "\n",
    "\n",
    "# Select the data (input) columns\n",
    "data_list = ['age', 'sex', 'cp','trestbps', 'chol', 'fbs','restecg',\n",
    "             'thalac','exang','oldpeak','slope','ca','thal']\n",
    "data = dataframe[data_list]\n",
    "\n",
    "# Scale the data\n",
    "data_min = data.min()\n",
    "data_max = data.max()\n",
    "data_norm = (data - data_min)/(data_max - data_min)\n",
    "\n",
    "# Another way to scale\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#data_norm = scaler.fit_transform(data.values)\n",
    "\n",
    "# Save the data\n",
    "#np.save('case_1_data.npy', data_norm)\n",
    "\n",
    "# Select the labels (output)\n",
    "labels = dataframe['num']\n",
    "\n",
    "# Code labels to categorical output\n",
    "one_hot_labels = to_categorical(labels)\n",
    "\n",
    "# Save categorical (one hot coded) labels\n",
    "#np.save('case_1_one_hot_labels.npy', one_hot_labels)\n",
    "\n",
    "# Make binary labels (diseased or not diseased)\n",
    "bin_labels = 1.0*(labels > 0.0)\n",
    "\n",
    "# Save binary labels\n",
    "#np.save('case_1_bin_labels.npy', bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 76, 227, 227)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data = data_norm[:200]\n",
    "#val_data = data_norm[200:]\n",
    "#test_labels = bin_labels[:200]\n",
    "#val_labels = bin_labels[200:]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,val_data,train_label,val_label = train_test_split(data_norm,\n",
    "                                                               bin_labels,\n",
    "                                                               test_size=0.25,\n",
    "                                                               random_state=42)\n",
    "\n",
    "len(val_data),len(val_label),len(train_data),len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76 samples, validate on 76 samples\n",
      "Epoch 1/300\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.6978 - acc: 0.4342 - val_loss: 0.6684 - val_acc: 0.5526\n",
      "Epoch 2/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.6647 - acc: 0.5921 - val_loss: 0.6474 - val_acc: 0.6053\n",
      "Epoch 3/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.6441 - acc: 0.6316 - val_loss: 0.6312 - val_acc: 0.6447\n",
      "Epoch 4/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.6282 - acc: 0.6711 - val_loss: 0.6163 - val_acc: 0.6974\n",
      "Epoch 5/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.6148 - acc: 0.6974 - val_loss: 0.6047 - val_acc: 0.7237\n",
      "Epoch 6/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.6022 - acc: 0.7237 - val_loss: 0.5931 - val_acc: 0.7368\n",
      "Epoch 7/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.5908 - acc: 0.7368 - val_loss: 0.5822 - val_acc: 0.7500\n",
      "Epoch 8/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.5806 - acc: 0.7500 - val_loss: 0.5718 - val_acc: 0.7895\n",
      "Epoch 9/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.5700 - acc: 0.7895 - val_loss: 0.5613 - val_acc: 0.8026\n",
      "Epoch 10/300\n",
      "76/76 [==============================] - 0s 119us/step - loss: 0.5604 - acc: 0.8026 - val_loss: 0.5522 - val_acc: 0.8026\n",
      "Epoch 11/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.5516 - acc: 0.7895 - val_loss: 0.5442 - val_acc: 0.8421\n",
      "Epoch 12/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.5424 - acc: 0.8158 - val_loss: 0.5350 - val_acc: 0.8553\n",
      "Epoch 13/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.5333 - acc: 0.8553 - val_loss: 0.5259 - val_acc: 0.8553\n",
      "Epoch 14/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.5240 - acc: 0.8553 - val_loss: 0.5167 - val_acc: 0.8684\n",
      "Epoch 15/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.5193 - acc: 0.8684 - val_loss: 0.5095 - val_acc: 0.8553\n",
      "Epoch 16/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.5094 - acc: 0.8553 - val_loss: 0.5018 - val_acc: 0.8684\n",
      "Epoch 17/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.5012 - acc: 0.8684 - val_loss: 0.4944 - val_acc: 0.8684\n",
      "Epoch 18/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.4936 - acc: 0.8684 - val_loss: 0.4874 - val_acc: 0.8684\n",
      "Epoch 19/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.4862 - acc: 0.8684 - val_loss: 0.4804 - val_acc: 0.8684\n",
      "Epoch 20/300\n",
      "76/76 [==============================] - 0s 145us/step - loss: 0.4799 - acc: 0.8684 - val_loss: 0.4730 - val_acc: 0.8684\n",
      "Epoch 21/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.4718 - acc: 0.8684 - val_loss: 0.4652 - val_acc: 0.8816\n",
      "Epoch 22/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.4639 - acc: 0.8816 - val_loss: 0.4579 - val_acc: 0.8816\n",
      "Epoch 23/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.4581 - acc: 0.8684 - val_loss: 0.4508 - val_acc: 0.8816\n",
      "Epoch 24/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.4494 - acc: 0.8816 - val_loss: 0.4425 - val_acc: 0.8684\n",
      "Epoch 25/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.4421 - acc: 0.8684 - val_loss: 0.4350 - val_acc: 0.8684\n",
      "Epoch 26/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.4337 - acc: 0.8684 - val_loss: 0.4274 - val_acc: 0.8816\n",
      "Epoch 27/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.4262 - acc: 0.8816 - val_loss: 0.4199 - val_acc: 0.8816\n",
      "Epoch 28/300\n",
      "76/76 [==============================] - 0s 158us/step - loss: 0.4221 - acc: 0.8816 - val_loss: 0.4127 - val_acc: 0.8816\n",
      "Epoch 29/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.4125 - acc: 0.8684 - val_loss: 0.4054 - val_acc: 0.8816\n",
      "Epoch 30/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.4071 - acc: 0.8816 - val_loss: 0.3989 - val_acc: 0.8816\n",
      "Epoch 31/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.3992 - acc: 0.8816 - val_loss: 0.3925 - val_acc: 0.8816\n",
      "Epoch 32/300\n",
      "76/76 [==============================] - 0s 184us/step - loss: 0.3943 - acc: 0.8816 - val_loss: 0.3866 - val_acc: 0.8816\n",
      "Epoch 33/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.3861 - acc: 0.8816 - val_loss: 0.3803 - val_acc: 0.8684\n",
      "Epoch 34/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.3796 - acc: 0.8684 - val_loss: 0.3739 - val_acc: 0.8684\n",
      "Epoch 35/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.3735 - acc: 0.8684 - val_loss: 0.3683 - val_acc: 0.8684\n",
      "Epoch 36/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.3708 - acc: 0.8684 - val_loss: 0.3628 - val_acc: 0.8684\n",
      "Epoch 37/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.3632 - acc: 0.8816 - val_loss: 0.3578 - val_acc: 0.8684\n",
      "Epoch 38/300\n",
      "76/76 [==============================] - 0s 171us/step - loss: 0.3590 - acc: 0.8816 - val_loss: 0.3532 - val_acc: 0.8947\n",
      "Epoch 39/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.3544 - acc: 0.9079 - val_loss: 0.3485 - val_acc: 0.8947\n",
      "Epoch 40/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.3478 - acc: 0.9079 - val_loss: 0.3435 - val_acc: 0.9079\n",
      "Epoch 41/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.3432 - acc: 0.9079 - val_loss: 0.3382 - val_acc: 0.9079\n",
      "Epoch 42/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.3380 - acc: 0.9079 - val_loss: 0.3331 - val_acc: 0.9079\n",
      "Epoch 43/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.3336 - acc: 0.9079 - val_loss: 0.3286 - val_acc: 0.9079\n",
      "Epoch 44/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.3326 - acc: 0.9079 - val_loss: 0.3238 - val_acc: 0.9079\n",
      "Epoch 45/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.3239 - acc: 0.9079 - val_loss: 0.3197 - val_acc: 0.9079\n",
      "Epoch 46/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.3213 - acc: 0.9079 - val_loss: 0.3163 - val_acc: 0.9079\n",
      "Epoch 47/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.3166 - acc: 0.9079 - val_loss: 0.3119 - val_acc: 0.9079\n",
      "Epoch 48/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.3115 - acc: 0.9079 - val_loss: 0.3076 - val_acc: 0.9079\n",
      "Epoch 49/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.3079 - acc: 0.9079 - val_loss: 0.3033 - val_acc: 0.9079\n",
      "Epoch 50/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.3063 - acc: 0.9079 - val_loss: 0.2996 - val_acc: 0.9079\n",
      "Epoch 51/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.3008 - acc: 0.9079 - val_loss: 0.2959 - val_acc: 0.9079\n",
      "Epoch 52/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.2989 - acc: 0.9079 - val_loss: 0.2937 - val_acc: 0.9079\n",
      "Epoch 53/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2936 - acc: 0.9079 - val_loss: 0.2895 - val_acc: 0.9079\n",
      "Epoch 54/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2898 - acc: 0.9079 - val_loss: 0.2864 - val_acc: 0.9079\n",
      "Epoch 55/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2870 - acc: 0.9079 - val_loss: 0.2832 - val_acc: 0.9079\n",
      "Epoch 56/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.2840 - acc: 0.9079 - val_loss: 0.2802 - val_acc: 0.9079\n",
      "Epoch 57/300\n",
      "76/76 [==============================] - 0s 79us/step - loss: 0.2814 - acc: 0.9079 - val_loss: 0.2774 - val_acc: 0.9079\n",
      "Epoch 58/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.2799 - acc: 0.9079 - val_loss: 0.2744 - val_acc: 0.9079\n",
      "Epoch 59/300\n",
      "76/76 [==============================] - 0s 79us/step - loss: 0.2760 - acc: 0.9079 - val_loss: 0.2721 - val_acc: 0.9079\n",
      "Epoch 60/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2729 - acc: 0.9079 - val_loss: 0.2691 - val_acc: 0.9079\n",
      "Epoch 61/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.2700 - acc: 0.9079 - val_loss: 0.2671 - val_acc: 0.9079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2681 - acc: 0.9079 - val_loss: 0.2638 - val_acc: 0.9079\n",
      "Epoch 63/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2667 - acc: 0.9079 - val_loss: 0.2613 - val_acc: 0.9079\n",
      "Epoch 64/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2621 - acc: 0.9079 - val_loss: 0.2589 - val_acc: 0.9079\n",
      "Epoch 65/300\n",
      "76/76 [==============================] - 0s 158us/step - loss: 0.2615 - acc: 0.9079 - val_loss: 0.2568 - val_acc: 0.9079\n",
      "Epoch 66/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2589 - acc: 0.9079 - val_loss: 0.2551 - val_acc: 0.9079\n",
      "Epoch 67/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2606 - acc: 0.9079 - val_loss: 0.2529 - val_acc: 0.9079\n",
      "Epoch 68/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2546 - acc: 0.9079 - val_loss: 0.2506 - val_acc: 0.9079\n",
      "Epoch 69/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2616 - acc: 0.9079 - val_loss: 0.2495 - val_acc: 0.9079\n",
      "Epoch 70/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2499 - acc: 0.9079 - val_loss: 0.2477 - val_acc: 0.9079\n",
      "Epoch 71/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.2497 - acc: 0.9079 - val_loss: 0.2467 - val_acc: 0.9079\n",
      "Epoch 72/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2509 - acc: 0.9079 - val_loss: 0.2459 - val_acc: 0.9079\n",
      "Epoch 73/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2473 - acc: 0.9079 - val_loss: 0.2437 - val_acc: 0.9211\n",
      "Epoch 74/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2473 - acc: 0.9079 - val_loss: 0.2426 - val_acc: 0.9079\n",
      "Epoch 75/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2505 - acc: 0.9079 - val_loss: 0.2414 - val_acc: 0.9211\n",
      "Epoch 76/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2426 - acc: 0.9211 - val_loss: 0.2401 - val_acc: 0.9211\n",
      "Epoch 77/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2436 - acc: 0.9211 - val_loss: 0.2390 - val_acc: 0.9211\n",
      "Epoch 78/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2403 - acc: 0.9079 - val_loss: 0.2374 - val_acc: 0.9211\n",
      "Epoch 79/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2389 - acc: 0.9211 - val_loss: 0.2357 - val_acc: 0.9211\n",
      "Epoch 80/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2375 - acc: 0.9211 - val_loss: 0.2342 - val_acc: 0.9211\n",
      "Epoch 81/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2356 - acc: 0.9211 - val_loss: 0.2328 - val_acc: 0.9211\n",
      "Epoch 82/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.2338 - acc: 0.9211 - val_loss: 0.2315 - val_acc: 0.9211\n",
      "Epoch 83/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.2328 - acc: 0.9211 - val_loss: 0.2300 - val_acc: 0.9211\n",
      "Epoch 84/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.2320 - acc: 0.9211 - val_loss: 0.2292 - val_acc: 0.9079\n",
      "Epoch 85/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2302 - acc: 0.9211 - val_loss: 0.2274 - val_acc: 0.9211\n",
      "Epoch 86/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2339 - acc: 0.9211 - val_loss: 0.2260 - val_acc: 0.9211\n",
      "Epoch 87/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2270 - acc: 0.9211 - val_loss: 0.2244 - val_acc: 0.9211\n",
      "Epoch 88/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2353 - acc: 0.9079 - val_loss: 0.2240 - val_acc: 0.9211\n",
      "Epoch 89/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2246 - acc: 0.9211 - val_loss: 0.2225 - val_acc: 0.9211\n",
      "Epoch 90/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2234 - acc: 0.9211 - val_loss: 0.2215 - val_acc: 0.9211\n",
      "Epoch 91/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2237 - acc: 0.9211 - val_loss: 0.2205 - val_acc: 0.9211\n",
      "Epoch 92/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2235 - acc: 0.9211 - val_loss: 0.2201 - val_acc: 0.9211\n",
      "Epoch 93/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2224 - acc: 0.9211 - val_loss: 0.2186 - val_acc: 0.9211\n",
      "Epoch 94/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2193 - acc: 0.9211 - val_loss: 0.2165 - val_acc: 0.9211\n",
      "Epoch 95/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2183 - acc: 0.9211 - val_loss: 0.2153 - val_acc: 0.9211\n",
      "Epoch 96/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2164 - acc: 0.9211 - val_loss: 0.2139 - val_acc: 0.9211\n",
      "Epoch 97/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2151 - acc: 0.9211 - val_loss: 0.2128 - val_acc: 0.9211\n",
      "Epoch 98/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2206 - acc: 0.8816 - val_loss: 0.2118 - val_acc: 0.9211\n",
      "Epoch 99/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.2133 - acc: 0.9211 - val_loss: 0.2106 - val_acc: 0.9211\n",
      "Epoch 100/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2134 - acc: 0.9211 - val_loss: 0.2098 - val_acc: 0.9342\n",
      "Epoch 101/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2120 - acc: 0.9342 - val_loss: 0.2092 - val_acc: 0.9474\n",
      "Epoch 102/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2154 - acc: 0.9211 - val_loss: 0.2074 - val_acc: 0.9342\n",
      "Epoch 103/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2100 - acc: 0.9342 - val_loss: 0.2062 - val_acc: 0.9211\n",
      "Epoch 104/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2076 - acc: 0.9211 - val_loss: 0.2056 - val_acc: 0.9342\n",
      "Epoch 105/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2070 - acc: 0.9211 - val_loss: 0.2041 - val_acc: 0.9342\n",
      "Epoch 106/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2122 - acc: 0.9211 - val_loss: 0.2044 - val_acc: 0.9211\n",
      "Epoch 107/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2054 - acc: 0.9211 - val_loss: 0.2026 - val_acc: 0.9342\n",
      "Epoch 108/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2039 - acc: 0.9342 - val_loss: 0.2017 - val_acc: 0.9342\n",
      "Epoch 109/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2057 - acc: 0.9211 - val_loss: 0.2007 - val_acc: 0.9342\n",
      "Epoch 110/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.2023 - acc: 0.9342 - val_loss: 0.2003 - val_acc: 0.9474\n",
      "Epoch 111/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.2065 - acc: 0.9211 - val_loss: 0.1999 - val_acc: 0.9342\n",
      "Epoch 112/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.2027 - acc: 0.9474 - val_loss: 0.1998 - val_acc: 0.9342\n",
      "Epoch 113/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.2014 - acc: 0.9342 - val_loss: 0.1976 - val_acc: 0.9342\n",
      "Epoch 114/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1997 - acc: 0.9342 - val_loss: 0.1968 - val_acc: 0.9342\n",
      "Epoch 115/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.1989 - acc: 0.9211 - val_loss: 0.1956 - val_acc: 0.9342\n",
      "Epoch 116/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1976 - acc: 0.9342 - val_loss: 0.1947 - val_acc: 0.9342\n",
      "Epoch 117/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1970 - acc: 0.9342 - val_loss: 0.1943 - val_acc: 0.9474\n",
      "Epoch 118/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.1977 - acc: 0.9342 - val_loss: 0.1942 - val_acc: 0.9342\n",
      "Epoch 119/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1983 - acc: 0.9211 - val_loss: 0.1945 - val_acc: 0.9342\n",
      "Epoch 120/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1965 - acc: 0.9342 - val_loss: 0.1935 - val_acc: 0.9342\n",
      "Epoch 121/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1959 - acc: 0.9079 - val_loss: 0.1915 - val_acc: 0.9342\n",
      "Epoch 122/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1930 - acc: 0.9342 - val_loss: 0.1912 - val_acc: 0.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1926 - acc: 0.9342 - val_loss: 0.1889 - val_acc: 0.9342\n",
      "Epoch 124/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1916 - acc: 0.9342 - val_loss: 0.1892 - val_acc: 0.9342\n",
      "Epoch 125/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1905 - acc: 0.9342 - val_loss: 0.1875 - val_acc: 0.9342\n",
      "Epoch 126/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1935 - acc: 0.9342 - val_loss: 0.1870 - val_acc: 0.9342\n",
      "Epoch 127/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1917 - acc: 0.9342 - val_loss: 0.1872 - val_acc: 0.9342\n",
      "Epoch 128/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1894 - acc: 0.9342 - val_loss: 0.1853 - val_acc: 0.9342\n",
      "Epoch 129/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1874 - acc: 0.9342 - val_loss: 0.1852 - val_acc: 0.9342\n",
      "Epoch 130/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1860 - acc: 0.9342 - val_loss: 0.1841 - val_acc: 0.9342\n",
      "Epoch 131/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1855 - acc: 0.9342 - val_loss: 0.1833 - val_acc: 0.9342\n",
      "Epoch 132/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1855 - acc: 0.9474 - val_loss: 0.1840 - val_acc: 0.9342\n",
      "Epoch 133/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1851 - acc: 0.9342 - val_loss: 0.1817 - val_acc: 0.9342\n",
      "Epoch 134/300\n",
      "76/76 [==============================] - 0s 79us/step - loss: 0.1826 - acc: 0.9342 - val_loss: 0.1812 - val_acc: 0.9342\n",
      "Epoch 135/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1844 - acc: 0.9342 - val_loss: 0.1814 - val_acc: 0.9342\n",
      "Epoch 136/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1841 - acc: 0.9342 - val_loss: 0.1803 - val_acc: 0.9342\n",
      "Epoch 137/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1817 - acc: 0.9342 - val_loss: 0.1788 - val_acc: 0.9342\n",
      "Epoch 138/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1802 - acc: 0.9342 - val_loss: 0.1781 - val_acc: 0.9342\n",
      "Epoch 139/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1809 - acc: 0.9342 - val_loss: 0.1780 - val_acc: 0.9342\n",
      "Epoch 140/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1805 - acc: 0.9342 - val_loss: 0.1766 - val_acc: 0.9342\n",
      "Epoch 141/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1798 - acc: 0.9342 - val_loss: 0.1761 - val_acc: 0.9342\n",
      "Epoch 142/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1790 - acc: 0.9342 - val_loss: 0.1759 - val_acc: 0.9342\n",
      "Epoch 143/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1776 - acc: 0.9342 - val_loss: 0.1748 - val_acc: 0.9342\n",
      "Epoch 144/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1774 - acc: 0.9211 - val_loss: 0.1745 - val_acc: 0.9342\n",
      "Epoch 145/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1758 - acc: 0.9342 - val_loss: 0.1731 - val_acc: 0.9342\n",
      "Epoch 146/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1781 - acc: 0.9474 - val_loss: 0.1723 - val_acc: 0.9342\n",
      "Epoch 147/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1781 - acc: 0.9342 - val_loss: 0.1716 - val_acc: 0.9342\n",
      "Epoch 148/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1756 - acc: 0.9342 - val_loss: 0.1723 - val_acc: 0.9342\n",
      "Epoch 149/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1747 - acc: 0.9474 - val_loss: 0.1704 - val_acc: 0.9342\n",
      "Epoch 150/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1737 - acc: 0.9342 - val_loss: 0.1709 - val_acc: 0.9342\n",
      "Epoch 151/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1745 - acc: 0.9342 - val_loss: 0.1693 - val_acc: 0.9342\n",
      "Epoch 152/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1748 - acc: 0.9342 - val_loss: 0.1686 - val_acc: 0.9342\n",
      "Epoch 153/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1713 - acc: 0.9342 - val_loss: 0.1683 - val_acc: 0.9342\n",
      "Epoch 154/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1697 - acc: 0.9342 - val_loss: 0.1677 - val_acc: 0.9342\n",
      "Epoch 155/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1687 - acc: 0.9342 - val_loss: 0.1666 - val_acc: 0.9342\n",
      "Epoch 156/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1695 - acc: 0.9211 - val_loss: 0.1672 - val_acc: 0.9342\n",
      "Epoch 157/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1677 - acc: 0.9342 - val_loss: 0.1656 - val_acc: 0.9342\n",
      "Epoch 158/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1686 - acc: 0.9342 - val_loss: 0.1662 - val_acc: 0.9342\n",
      "Epoch 159/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1691 - acc: 0.9211 - val_loss: 0.1644 - val_acc: 0.9342\n",
      "Epoch 160/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1677 - acc: 0.9342 - val_loss: 0.1656 - val_acc: 0.9342\n",
      "Epoch 161/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1668 - acc: 0.9211 - val_loss: 0.1642 - val_acc: 0.9342\n",
      "Epoch 162/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1697 - acc: 0.9342 - val_loss: 0.1634 - val_acc: 0.9342\n",
      "Epoch 163/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1644 - acc: 0.9342 - val_loss: 0.1621 - val_acc: 0.9342\n",
      "Epoch 164/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1632 - acc: 0.9342 - val_loss: 0.1620 - val_acc: 0.9474\n",
      "Epoch 165/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1660 - acc: 0.9342 - val_loss: 0.1626 - val_acc: 0.9342\n",
      "Epoch 166/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1666 - acc: 0.9211 - val_loss: 0.1633 - val_acc: 0.9474\n",
      "Epoch 167/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1688 - acc: 0.9474 - val_loss: 0.1604 - val_acc: 0.9474\n",
      "Epoch 168/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1633 - acc: 0.9342 - val_loss: 0.1605 - val_acc: 0.9342\n",
      "Epoch 169/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1609 - acc: 0.9342 - val_loss: 0.1591 - val_acc: 0.9342\n",
      "Epoch 170/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1596 - acc: 0.9342 - val_loss: 0.1585 - val_acc: 0.9342\n",
      "Epoch 171/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1602 - acc: 0.9342 - val_loss: 0.1582 - val_acc: 0.9342\n",
      "Epoch 172/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1606 - acc: 0.9342 - val_loss: 0.1584 - val_acc: 0.9342\n",
      "Epoch 173/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1593 - acc: 0.9342 - val_loss: 0.1574 - val_acc: 0.9342\n",
      "Epoch 174/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1634 - acc: 0.9342 - val_loss: 0.1570 - val_acc: 0.9474\n",
      "Epoch 175/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1585 - acc: 0.9474 - val_loss: 0.1570 - val_acc: 0.9342\n",
      "Epoch 176/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1580 - acc: 0.9342 - val_loss: 0.1559 - val_acc: 0.9342\n",
      "Epoch 177/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1573 - acc: 0.9342 - val_loss: 0.1551 - val_acc: 0.9342\n",
      "Epoch 178/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1562 - acc: 0.9474 - val_loss: 0.1548 - val_acc: 0.9342\n",
      "Epoch 179/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1582 - acc: 0.9342 - val_loss: 0.1542 - val_acc: 0.9342\n",
      "Epoch 180/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1593 - acc: 0.9342 - val_loss: 0.1556 - val_acc: 0.9342\n",
      "Epoch 181/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1568 - acc: 0.9342 - val_loss: 0.1527 - val_acc: 0.9474\n",
      "Epoch 182/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1580 - acc: 0.9342 - val_loss: 0.1525 - val_acc: 0.9342\n",
      "Epoch 183/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1560 - acc: 0.9211 - val_loss: 0.1518 - val_acc: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1540 - acc: 0.9342 - val_loss: 0.1518 - val_acc: 0.9342\n",
      "Epoch 185/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1547 - acc: 0.9342 - val_loss: 0.1507 - val_acc: 0.9474\n",
      "Epoch 186/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1529 - acc: 0.9474 - val_loss: 0.1507 - val_acc: 0.9342\n",
      "Epoch 187/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1523 - acc: 0.9342 - val_loss: 0.1499 - val_acc: 0.9474\n",
      "Epoch 188/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1545 - acc: 0.9474 - val_loss: 0.1516 - val_acc: 0.9342\n",
      "Epoch 189/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1530 - acc: 0.9342 - val_loss: 0.1496 - val_acc: 0.9342\n",
      "Epoch 190/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1521 - acc: 0.9342 - val_loss: 0.1485 - val_acc: 0.9342\n",
      "Epoch 191/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1513 - acc: 0.9342 - val_loss: 0.1484 - val_acc: 0.9342\n",
      "Epoch 192/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1498 - acc: 0.9342 - val_loss: 0.1478 - val_acc: 0.9342\n",
      "Epoch 193/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1534 - acc: 0.9342 - val_loss: 0.1475 - val_acc: 0.9342\n",
      "Epoch 194/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1486 - acc: 0.9342 - val_loss: 0.1465 - val_acc: 0.9474\n",
      "Epoch 195/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1475 - acc: 0.9474 - val_loss: 0.1459 - val_acc: 0.9342\n",
      "Epoch 196/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1473 - acc: 0.9342 - val_loss: 0.1455 - val_acc: 0.9474\n",
      "Epoch 197/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1497 - acc: 0.9474 - val_loss: 0.1457 - val_acc: 0.9342\n",
      "Epoch 198/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1487 - acc: 0.9342 - val_loss: 0.1451 - val_acc: 0.9342\n",
      "Epoch 199/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1487 - acc: 0.9342 - val_loss: 0.1451 - val_acc: 0.9342\n",
      "Epoch 200/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1471 - acc: 0.9342 - val_loss: 0.1441 - val_acc: 0.9342\n",
      "Epoch 201/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1454 - acc: 0.9342 - val_loss: 0.1430 - val_acc: 0.9474\n",
      "Epoch 202/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1458 - acc: 0.9474 - val_loss: 0.1431 - val_acc: 0.9474\n",
      "Epoch 203/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1467 - acc: 0.9342 - val_loss: 0.1429 - val_acc: 0.9342\n",
      "Epoch 204/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1508 - acc: 0.9342 - val_loss: 0.1454 - val_acc: 0.9474\n",
      "Epoch 205/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1498 - acc: 0.9342 - val_loss: 0.1444 - val_acc: 0.9342\n",
      "Epoch 206/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1464 - acc: 0.9342 - val_loss: 0.1410 - val_acc: 0.9474\n",
      "Epoch 207/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1439 - acc: 0.9474 - val_loss: 0.1404 - val_acc: 0.9474\n",
      "Epoch 208/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1440 - acc: 0.9342 - val_loss: 0.1411 - val_acc: 0.9342\n",
      "Epoch 209/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1426 - acc: 0.9474 - val_loss: 0.1401 - val_acc: 0.9342\n",
      "Epoch 210/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1458 - acc: 0.9342 - val_loss: 0.1427 - val_acc: 0.9342\n",
      "Epoch 211/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1431 - acc: 0.9342 - val_loss: 0.1396 - val_acc: 0.9342\n",
      "Epoch 212/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1424 - acc: 0.9342 - val_loss: 0.1391 - val_acc: 0.9342\n",
      "Epoch 213/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1411 - acc: 0.9474 - val_loss: 0.1388 - val_acc: 0.9342\n",
      "Epoch 214/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1404 - acc: 0.9342 - val_loss: 0.1378 - val_acc: 0.9342\n",
      "Epoch 215/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1424 - acc: 0.9342 - val_loss: 0.1396 - val_acc: 0.9342\n",
      "Epoch 216/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1424 - acc: 0.9342 - val_loss: 0.1389 - val_acc: 0.9342\n",
      "Epoch 217/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1429 - acc: 0.9474 - val_loss: 0.1400 - val_acc: 0.9342\n",
      "Epoch 218/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1401 - acc: 0.9342 - val_loss: 0.1359 - val_acc: 0.9474\n",
      "Epoch 219/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1417 - acc: 0.9342 - val_loss: 0.1362 - val_acc: 0.9342\n",
      "Epoch 220/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1408 - acc: 0.9474 - val_loss: 0.1367 - val_acc: 0.9342\n",
      "Epoch 221/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1379 - acc: 0.9342 - val_loss: 0.1353 - val_acc: 0.9342\n",
      "Epoch 222/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1362 - acc: 0.9342 - val_loss: 0.1347 - val_acc: 0.9474\n",
      "Epoch 223/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1383 - acc: 0.9342 - val_loss: 0.1359 - val_acc: 0.9342\n",
      "Epoch 224/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1369 - acc: 0.9342 - val_loss: 0.1341 - val_acc: 0.9342\n",
      "Epoch 225/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1399 - acc: 0.9342 - val_loss: 0.1335 - val_acc: 0.9474\n",
      "Epoch 226/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1367 - acc: 0.9474 - val_loss: 0.1328 - val_acc: 0.9474\n",
      "Epoch 227/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1377 - acc: 0.9474 - val_loss: 0.1333 - val_acc: 0.9342\n",
      "Epoch 228/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1360 - acc: 0.9342 - val_loss: 0.1321 - val_acc: 0.9474\n",
      "Epoch 229/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1345 - acc: 0.9342 - val_loss: 0.1327 - val_acc: 0.9342\n",
      "Epoch 230/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1331 - acc: 0.9342 - val_loss: 0.1315 - val_acc: 0.9474\n",
      "Epoch 231/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1337 - acc: 0.9342 - val_loss: 0.1306 - val_acc: 0.9342\n",
      "Epoch 232/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1335 - acc: 0.9342 - val_loss: 0.1317 - val_acc: 0.9342\n",
      "Epoch 233/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1333 - acc: 0.9342 - val_loss: 0.1302 - val_acc: 0.9474\n",
      "Epoch 234/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1359 - acc: 0.9342 - val_loss: 0.1300 - val_acc: 0.9342\n",
      "Epoch 235/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1308 - acc: 0.9342 - val_loss: 0.1293 - val_acc: 0.9474\n",
      "Epoch 236/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1309 - acc: 0.9474 - val_loss: 0.1289 - val_acc: 0.9474\n",
      "Epoch 237/300\n",
      "76/76 [==============================] - 0s 157us/step - loss: 0.1310 - acc: 0.9474 - val_loss: 0.1292 - val_acc: 0.9474\n",
      "Epoch 238/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1324 - acc: 0.9474 - val_loss: 0.1284 - val_acc: 0.9474\n",
      "Epoch 239/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1303 - acc: 0.9474 - val_loss: 0.1280 - val_acc: 0.9342\n",
      "Epoch 240/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1333 - acc: 0.9342 - val_loss: 0.1283 - val_acc: 0.9474\n",
      "Epoch 241/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1288 - acc: 0.9474 - val_loss: 0.1268 - val_acc: 0.9474\n",
      "Epoch 242/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1327 - acc: 0.9342 - val_loss: 0.1287 - val_acc: 0.9342\n",
      "Epoch 243/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1326 - acc: 0.9342 - val_loss: 0.1277 - val_acc: 0.9342\n",
      "Epoch 244/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1290 - acc: 0.9342 - val_loss: 0.1267 - val_acc: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1322 - acc: 0.9342 - val_loss: 0.1274 - val_acc: 0.9342\n",
      "Epoch 246/300\n",
      "76/76 [==============================] - 0s 145us/step - loss: 0.1297 - acc: 0.9342 - val_loss: 0.1259 - val_acc: 0.9474\n",
      "Epoch 247/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1272 - acc: 0.9474 - val_loss: 0.1252 - val_acc: 0.9474\n",
      "Epoch 248/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1271 - acc: 0.9474 - val_loss: 0.1245 - val_acc: 0.9474\n",
      "Epoch 249/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1279 - acc: 0.9342 - val_loss: 0.1256 - val_acc: 0.9474\n",
      "Epoch 250/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1261 - acc: 0.9474 - val_loss: 0.1244 - val_acc: 0.9474\n",
      "Epoch 251/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1285 - acc: 0.9342 - val_loss: 0.1236 - val_acc: 0.9474\n",
      "Epoch 252/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1273 - acc: 0.9474 - val_loss: 0.1243 - val_acc: 0.9342\n",
      "Epoch 253/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1295 - acc: 0.9342 - val_loss: 0.1262 - val_acc: 0.9342\n",
      "Epoch 254/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1268 - acc: 0.9342 - val_loss: 0.1230 - val_acc: 0.9474\n",
      "Epoch 255/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1243 - acc: 0.9474 - val_loss: 0.1226 - val_acc: 0.9474\n",
      "Epoch 256/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1274 - acc: 0.9474 - val_loss: 0.1239 - val_acc: 0.9342\n",
      "Epoch 257/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1237 - acc: 0.9342 - val_loss: 0.1220 - val_acc: 0.9474\n",
      "Epoch 258/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1235 - acc: 0.9474 - val_loss: 0.1215 - val_acc: 0.9474\n",
      "Epoch 259/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1227 - acc: 0.9474 - val_loss: 0.1214 - val_acc: 0.9474\n",
      "Epoch 260/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1233 - acc: 0.9342 - val_loss: 0.1222 - val_acc: 0.9605\n",
      "Epoch 261/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1241 - acc: 0.9474 - val_loss: 0.1205 - val_acc: 0.9474\n",
      "Epoch 262/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1276 - acc: 0.9342 - val_loss: 0.1207 - val_acc: 0.9342\n",
      "Epoch 263/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1216 - acc: 0.9342 - val_loss: 0.1203 - val_acc: 0.9474\n",
      "Epoch 264/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1224 - acc: 0.9474 - val_loss: 0.1200 - val_acc: 0.9474\n",
      "Epoch 265/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1211 - acc: 0.9474 - val_loss: 0.1192 - val_acc: 0.9474\n",
      "Epoch 266/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1208 - acc: 0.9474 - val_loss: 0.1195 - val_acc: 0.9474\n",
      "Epoch 267/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1250 - acc: 0.9342 - val_loss: 0.1201 - val_acc: 0.9605\n",
      "Epoch 268/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1200 - acc: 0.9605 - val_loss: 0.1184 - val_acc: 0.9474\n",
      "Epoch 269/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1256 - acc: 0.9342 - val_loss: 0.1184 - val_acc: 0.9474\n",
      "Epoch 270/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1241 - acc: 0.9474 - val_loss: 0.1178 - val_acc: 0.9474\n",
      "Epoch 271/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1190 - acc: 0.9474 - val_loss: 0.1175 - val_acc: 0.9474\n",
      "Epoch 272/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1229 - acc: 0.9342 - val_loss: 0.1171 - val_acc: 0.9474\n",
      "Epoch 273/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1323 - acc: 0.9342 - val_loss: 0.1173 - val_acc: 0.9342\n",
      "Epoch 274/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1223 - acc: 0.9342 - val_loss: 0.1180 - val_acc: 0.9605\n",
      "Epoch 275/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1191 - acc: 0.9605 - val_loss: 0.1168 - val_acc: 0.9474\n",
      "Epoch 276/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1197 - acc: 0.9342 - val_loss: 0.1167 - val_acc: 0.9605\n",
      "Epoch 277/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1175 - acc: 0.9605 - val_loss: 0.1158 - val_acc: 0.9474\n",
      "Epoch 278/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1210 - acc: 0.9474 - val_loss: 0.1158 - val_acc: 0.9474\n",
      "Epoch 279/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1190 - acc: 0.9474 - val_loss: 0.1154 - val_acc: 0.9474\n",
      "Epoch 280/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1213 - acc: 0.9474 - val_loss: 0.1177 - val_acc: 0.9342\n",
      "Epoch 281/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1209 - acc: 0.9342 - val_loss: 0.1156 - val_acc: 0.9474\n",
      "Epoch 282/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1176 - acc: 0.9474 - val_loss: 0.1146 - val_acc: 0.9474\n",
      "Epoch 283/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1177 - acc: 0.9474 - val_loss: 0.1148 - val_acc: 0.9605\n",
      "Epoch 284/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1207 - acc: 0.9474 - val_loss: 0.1142 - val_acc: 0.9342\n",
      "Epoch 285/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1294 - acc: 0.9342 - val_loss: 0.1136 - val_acc: 0.9474\n",
      "Epoch 286/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1147 - acc: 0.9474 - val_loss: 0.1135 - val_acc: 0.9605\n",
      "Epoch 287/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1176 - acc: 0.9474 - val_loss: 0.1142 - val_acc: 0.9605\n",
      "Epoch 288/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1164 - acc: 0.9605 - val_loss: 0.1132 - val_acc: 0.9474\n",
      "Epoch 289/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1159 - acc: 0.9474 - val_loss: 0.1129 - val_acc: 0.9342\n",
      "Epoch 290/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1154 - acc: 0.9342 - val_loss: 0.1128 - val_acc: 0.9605\n",
      "Epoch 291/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1222 - acc: 0.9342 - val_loss: 0.1121 - val_acc: 0.9605\n",
      "Epoch 292/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1129 - acc: 0.9605 - val_loss: 0.1114 - val_acc: 0.9605\n",
      "Epoch 293/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1178 - acc: 0.9342 - val_loss: 0.1116 - val_acc: 0.9342\n",
      "Epoch 294/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1138 - acc: 0.9474 - val_loss: 0.1115 - val_acc: 0.9605\n",
      "Epoch 295/300\n",
      "76/76 [==============================] - 0s 158us/step - loss: 0.1122 - acc: 0.9605 - val_loss: 0.1107 - val_acc: 0.9474\n",
      "Epoch 296/300\n",
      "76/76 [==============================] - 0s 92us/step - loss: 0.1126 - acc: 0.9474 - val_loss: 0.1108 - val_acc: 0.9342\n",
      "Epoch 297/300\n",
      "76/76 [==============================] - 0s 131us/step - loss: 0.1171 - acc: 0.9474 - val_loss: 0.1123 - val_acc: 0.9342\n",
      "Epoch 298/300\n",
      "76/76 [==============================] - 0s 105us/step - loss: 0.1170 - acc: 0.9342 - val_loss: 0.1101 - val_acc: 0.9605\n",
      "Epoch 299/300\n",
      "76/76 [==============================] - 0s 118us/step - loss: 0.1125 - acc: 0.9342 - val_loss: 0.1098 - val_acc: 0.9605\n",
      "Epoch 300/300\n",
      "76/76 [==============================] - 0s 144us/step - loss: 0.1139 - acc: 0.9474 - val_loss: 0.1106 - val_acc: 0.9605\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11064375211533747\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30,\n",
    "               activation='relu',\n",
    "               input_dim=13))\n",
    "model.add(Dense(30,\n",
    "               activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(test_data,\n",
    "                    test_label,\n",
    "                    epochs=300,\n",
    "                    batch_size=30,\n",
    "                    verbose=1,\n",
    "                    validation_data=(val_data,val_label)\n",
    "                   )\n",
    "h_dict = history.history\n",
    "epochs = range(1, len(h_dict['loss'])+1)\n",
    "\n",
    "plt.plot(epochs, h_dict['loss'], 'bo', label='Training loss')\n",
    "plt.plot(epochs, h_dict['val_loss'], 'b', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(h_dict['val_loss'][len(h_dict['val_loss'])-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss\n",
      "val_acc\n",
      "loss\n",
      "acc\n"
     ]
    }
   ],
   "source": [
    "for key, value in h_dict.items() :\n",
    "    print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960526317358017\n"
     ]
    }
   ],
   "source": [
    "plt.plot(epochs, h_dict['acc'], 'bo', label='Training acc')\n",
    "plt.plot(epochs, h_dict['val_acc'], 'b', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(h_dict['val_acc'][len(h_dict['val_acc'])-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
